{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70221507",
   "metadata": {},
   "source": [
    "# KPA User Data Management & Analysis\n",
    "\n",
    "This notebook provides tools for:\n",
    "- 🔧 Testing KPA API connectivity\n",
    "- 👥 Fetching and analyzing user data  \n",
    "- 📸 Testing photo integration\n",
    "- 📊 Data exploration and filtering\n",
    "- 📋 Export utilities for raffle system\n",
    "\n",
    "**Updated**: August 25, 2025 - After KPA integration optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f2cae54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Libraries imported successfully!\n",
      "🕒 Notebook initialized at: 2025-08-25 21:17:23\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from typing import Dict, List, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Set display options for better output\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"📦 Libraries imported successfully!\")\n",
    "print(f\"🕒 Notebook initialized at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d06fcb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 KPA API Configuration\n",
      "========================================\n",
      "API Base URL: https://api.kpaehs.com/v1\n",
      "Token Status: ✅ Found\n",
      "Token Preview: pTfES8COPXiB3fCCE0ud...\n",
      "🎯 Ready to test KPA connectivity!\n"
     ]
    }
   ],
   "source": [
    "# KPA API Configuration\n",
    "API_BASE = \"https://api.kpaehs.com/v1\"\n",
    "\n",
    "# Load KPA token from environment (try both variable names)\n",
    "KPA_TOKEN = os.getenv(\"KPA_TOKEN\") or os.getenv(\"KPA_API_TOKEN\")\n",
    "\n",
    "# Display configuration status\n",
    "print(\"🔧 KPA API Configuration\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"API Base URL: {API_BASE}\")\n",
    "print(f\"Token Status: {'✅ Found' if KPA_TOKEN else '❌ Missing'}\")\n",
    "\n",
    "if KPA_TOKEN:\n",
    "    print(f\"Token Preview: {KPA_TOKEN[:20]}...\")\n",
    "    print(\"🎯 Ready to test KPA connectivity!\")\n",
    "else:\n",
    "    print(\"⚠️  KPA_TOKEN or KPA_API_TOKEN environment variable not found\")\n",
    "    print(\"💡 Make sure your .env file or secrets are configured properly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89914322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔑 Loaded environment from: /workspaces/raffle-randomizer/secrets/.env\n",
      "🔍 Environment loading complete\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from secrets folder\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Try to load from secrets folder\n",
    "env_path = '/workspaces/raffle-randomizer/secrets/.env'\n",
    "if os.path.exists(env_path):\n",
    "    load_dotenv(env_path)\n",
    "    print(f\"🔑 Loaded environment from: {env_path}\")\n",
    "else:\n",
    "    print(\"⚠️ No .env file found in secrets folder\")\n",
    "\n",
    "# Also try loading from current directory\n",
    "load_dotenv()\n",
    "print(\"🔍 Environment loading complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbbdc569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Testing KPA API Integration\n",
      "==================================================\n",
      "📡 Testing users.list endpoint...\n",
      "Status Code: 200\n",
      "✅ KPA API connection successful!\n",
      "📋 Response type: <class 'dict'>\n",
      "📋 Response keys: ['users', 'columns', 'ok']\n",
      "Status Code: 200\n",
      "✅ KPA API connection successful!\n",
      "📋 Response type: <class 'dict'>\n",
      "📋 Response keys: ['users', 'columns', 'ok']\n"
     ]
    }
   ],
   "source": [
    "# Test KPA API Connectivity\n",
    "def test_kpa_integration():\n",
    "    \"\"\"Test KPA API connectivity and available endpoints\"\"\"\n",
    "    print(\"🔍 Testing KPA API Integration\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if not KPA_TOKEN:\n",
    "        print(\"❌ No KPA token available - cannot test\")\n",
    "        return None\n",
    "    \n",
    "    # Test basic connectivity with users.list\n",
    "    try:\n",
    "        print(\"📡 Testing users.list endpoint...\")\n",
    "        data = {\"token\": KPA_TOKEN}\n",
    "        response = requests.post(f\"{API_BASE}/users.list\", json=data, timeout=10)\n",
    "        \n",
    "        print(f\"Status Code: {response.status_code}\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(\"✅ KPA API connection successful!\")\n",
    "            \n",
    "            if isinstance(result, list):\n",
    "                print(f\"📊 Found {len(result)} users\")\n",
    "                if result:\n",
    "                    print(\"🔍 Sample user fields:\")\n",
    "                    sample_user = result[0]\n",
    "                    for key in sorted(sample_user.keys()):\n",
    "                        print(f\"  • {key}\")\n",
    "                return result\n",
    "            else:\n",
    "                print(f\"📋 Response type: {type(result)}\")\n",
    "                print(f\"📋 Response keys: {list(result.keys()) if isinstance(result, dict) else 'Not a dict'}\")\n",
    "                return result\n",
    "        else:\n",
    "            print(f\"❌ API Error: {response.status_code}\")\n",
    "            try:\n",
    "                error_data = response.json()\n",
    "                print(f\"Error details: {error_data}\")\n",
    "            except:\n",
    "                print(f\"Raw response: {response.text}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Connection failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Run the test\n",
    "kpa_data = test_kpa_integration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1d07ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze User Data\n",
    "print(\"📊 KPA API Response Analysis\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if kpa_data:\n",
    "    print(f\"📋 Response Type: {type(kpa_data)}\")\n",
    "    print(f\"📋 Response Keys: {list(kpa_data.keys()) if isinstance(kpa_data, dict) else 'Not a dict'}\")\n",
    "    \n",
    "    # Check if users are in a nested structure\n",
    "    if isinstance(kpa_data, dict) and 'users' in kpa_data:\n",
    "        users_list = kpa_data['users']\n",
    "        print(f\"\udc65 Found users list with {len(users_list)} users\")\n",
    "        \n",
    "        if users_list and len(users_list) > 0:\n",
    "            # Convert to DataFrame for easier analysis\n",
    "            df = pd.DataFrame(users_list)\n",
    "            \n",
    "            print(f\"📋 Available Fields: {len(df.columns)}\")\n",
    "            print(\"\\n🔍 Data Overview:\")\n",
    "            print(df.info())\n",
    "            \n",
    "            print(\"\\n📈 Column Summary:\")\n",
    "            for col in df.columns:\n",
    "                non_null_count = df[col].notna().sum()\n",
    "                print(f\"  • {col}: {non_null_count}/{len(df)} ({non_null_count/len(df)*100:.1f}%)\")\n",
    "            \n",
    "            # Look for photo fields\n",
    "            photo_fields = [col for col in df.columns if 'photo' in col.lower() or 'image' in col.lower() or 'picture' in col.lower()]\n",
    "            if photo_fields:\n",
    "                print(f\"\\n📸 Photo Fields Found: {photo_fields}\")\n",
    "                for field in photo_fields:\n",
    "                    photo_count = df[field].notna().sum()\n",
    "                    print(f\"  • {field}: {photo_count} users have photos\")\n",
    "            else:\n",
    "                print(\"\\n📸 No obvious photo fields found\")\n",
    "                print(\"🔍 Fields containing 'http' or URLs:\")\n",
    "                for col in df.columns:\n",
    "                    if df[col].dtype == 'object':\n",
    "                        url_count = df[col].astype(str).str.contains('http', na=False).sum()\n",
    "                        if url_count > 0:\n",
    "                            print(f\"  • {col}: {url_count} entries contain 'http'\")\n",
    "        else:\n",
    "            print(\"❌ Users list is empty\")\n",
    "    elif isinstance(kpa_data, list):\n",
    "        print(\"📊 Data appears to be a direct list\")\n",
    "        df = pd.DataFrame(kpa_data)\n",
    "        print(f\"👥 Total Users: {len(df)}\")\n",
    "        print(f\"📋 Available Fields: {len(df.columns)}\")\n",
    "    else:\n",
    "        print(\"❌ Unexpected data structure\")\n",
    "        print(f\"Data content: {kpa_data}\")\n",
    "else:\n",
    "    print(\"❌ No user data available for analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653de53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test KPA API with corrected parameter name\n",
    "def test_users_info_endpoint():\n",
    "    \"\"\"Test the users.info endpoint with correct 'id' parameter\"\"\"\n",
    "    print(\"🔧 Testing KPA users.info with corrected parameter\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if not KPA_TOKEN:\n",
    "        print(\"❌ No KPA token available\")\n",
    "        return None\n",
    "    \n",
    "    # Test with a sample user ID (using your example format)\n",
    "    test_id = \"6470af6754bfbc1d5ce9bb61\"  # Your example ID\n",
    "    \n",
    "    try:\n",
    "        # Test with corrected parameter name: \"id\" instead of \"user_id\"\n",
    "        data = {\"token\": KPA_TOKEN, \"id\": test_id}\n",
    "        response = requests.post(f\"{API_BASE}/users.info\", json=data, timeout=10)\n",
    "        \n",
    "        print(f\"📡 Testing with ID: {test_id}\")\n",
    "        print(f\"📋 Status Code: {response.status_code}\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(\"✅ users.info endpoint successful!\")\n",
    "            print(f\"📊 Response type: {type(result)}\")\n",
    "            print(f\"📋 Response keys: {list(result.keys()) if isinstance(result, dict) else 'Not a dict'}\")\n",
    "            \n",
    "            # Look for user data\n",
    "            if isinstance(result, dict):\n",
    "                if 'user' in result:\n",
    "                    user_data = result['user']\n",
    "                    print(f\"👤 User data found: {type(user_data)}\")\n",
    "                    if isinstance(user_data, dict):\n",
    "                        print(f\"📋 User fields: {list(user_data.keys())}\")\n",
    "                elif 'ok' in result:\n",
    "                    print(f\"🔍 API response OK: {result.get('ok')}\")\n",
    "                    \n",
    "            return result\n",
    "        else:\n",
    "            print(f\"❌ API Error: {response.status_code}\")\n",
    "            try:\n",
    "                error_data = response.json()\n",
    "                print(f\"💥 Error details: {error_data}\")\n",
    "            except:\n",
    "                print(f\"📄 Raw response: {response.text}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Request failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Run the test\n",
    "test_result = test_users_info_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162bfd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check of kpa_data structure\n",
    "print(\"🔍 Quick Data Check\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Type: {type(kpa_data)}\")\n",
    "if isinstance(kpa_data, dict):\n",
    "    print(f\"Keys: {list(kpa_data.keys())}\")\n",
    "    if 'users' in kpa_data:\n",
    "        print(f\"Users count: {len(kpa_data['users'])}\")\n",
    "        if kpa_data['users']:\n",
    "            print(f\"First user keys: {list(kpa_data['users'][0].keys())}\")\n",
    "elif isinstance(kpa_data, list):\n",
    "    print(f\"List length: {len(kpa_data)}\")\n",
    "else:\n",
    "    print(f\"Data: {kpa_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7783980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Photo Integration\n",
    "def test_photo_loading(sample_size=3):\n",
    "    \"\"\"Test photo loading for a sample of users\"\"\"\n",
    "    if not kpa_data:\n",
    "        print(\"❌ No user data available for photo testing\")\n",
    "        return\n",
    "    \n",
    "    print(\"📸 Testing Photo Loading\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Handle both list and dict structures\n",
    "    users_list = None\n",
    "    if isinstance(kpa_data, dict) and 'users' in kpa_data:\n",
    "        users_list = kpa_data['users']\n",
    "        print(f\"📊 Using users from API response ({len(users_list)} users)\")\n",
    "    elif isinstance(kpa_data, list):\n",
    "        users_list = kpa_data\n",
    "        print(f\"📊 Using direct user list ({len(users_list)} users)\")\n",
    "    else:\n",
    "        print(\"❌ Unexpected data structure for photo testing\")\n",
    "        return\n",
    "    \n",
    "    if not users_list:\n",
    "        print(\"❌ No users found for photo testing\")\n",
    "        return\n",
    "    \n",
    "    df = pd.DataFrame(users_list)\n",
    "    \n",
    "    # Find potential photo fields\n",
    "    photo_candidates = []\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            url_count = df[col].astype(str).str.contains('http', na=False).sum()\n",
    "            if url_count > 0:\n",
    "                photo_candidates.append((col, url_count))\n",
    "    \n",
    "    if not photo_candidates:\n",
    "        print(\"❌ No URL fields found for photo testing\")\n",
    "        return\n",
    "    \n",
    "    print(f\"🔍 Found {len(photo_candidates)} potential photo fields:\")\n",
    "    for field, count in photo_candidates:\n",
    "        print(f\"  • {field}: {count} URLs\")\n",
    "    \n",
    "    # Test the most promising field\n",
    "    best_field = max(photo_candidates, key=lambda x: x[1])[0]\n",
    "    print(f\"\\n🎯 Testing field: {best_field}\")\n",
    "    \n",
    "    # Get sample URLs\n",
    "    sample_urls = df[df[best_field].notna()][best_field].head(sample_size)\n",
    "    \n",
    "    for i, url in enumerate(sample_urls, 1):\n",
    "        print(f\"\\n📷 Testing photo {i}: {str(url)[:60]}...\")\n",
    "        try:\n",
    "            response = requests.get(str(url), timeout=10)\n",
    "            if response.status_code == 200:\n",
    "                content_type = response.headers.get('content-type', '')\n",
    "                size = len(response.content)\n",
    "                print(f\"  ✅ Success! Type: {content_type}, Size: {size:,} bytes\")\n",
    "            else:\n",
    "                print(f\"  ❌ Failed: HTTP {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Error: {str(e)}\")\n",
    "\n",
    "# Run photo test\n",
    "test_photo_loading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a96b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration & Filtering Tools\n",
    "def explore_user_data():\n",
    "    \"\"\"Interactive exploration of user data\"\"\"\n",
    "    if not kpa_data:\n",
    "        print(\"❌ No user data available\")\n",
    "        return\n",
    "    \n",
    "    print(\"🔍 User Data Explorer\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Handle both list and dict structures\n",
    "    users_list = None\n",
    "    if isinstance(kpa_data, dict) and 'users' in kpa_data:\n",
    "        users_list = kpa_data['users']\n",
    "        print(f\"📊 Using users from API response ({len(users_list)} users)\")\n",
    "    elif isinstance(kpa_data, list):\n",
    "        users_list = kpa_data\n",
    "        print(f\"📊 Using direct user list ({len(users_list)} users)\")\n",
    "    else:\n",
    "        print(\"❌ Unexpected data structure\")\n",
    "        return\n",
    "    \n",
    "    if not users_list:\n",
    "        print(\"❌ No users found\")\n",
    "        return\n",
    "    \n",
    "    df = pd.DataFrame(users_list)\n",
    "    \n",
    "    # Show sample records\n",
    "    print(\"\\n📋 Sample Records (first 3):\")\n",
    "    print(df.head(3).to_string())\n",
    "    \n",
    "    # Look for common fields useful for raffles\n",
    "    important_fields = ['name', 'first_name', 'last_name', 'email', 'department', \n",
    "                       'location', 'position', 'level', 'status', 'active']\n",
    "    \n",
    "    found_fields = [field for field in important_fields if field in df.columns]\n",
    "    print(f\"\\n🎯 Important Fields Found: {found_fields}\")\n",
    "    \n",
    "    # Check for location/department data\n",
    "    location_fields = [col for col in df.columns if any(word in col.lower() \n",
    "                      for word in ['location', 'site', 'office', 'building'])]\n",
    "    if location_fields:\n",
    "        print(f\"\\n📍 Location Fields: {location_fields}\")\n",
    "        for field in location_fields:\n",
    "            unique_values = df[field].nunique()\n",
    "            print(f\"  • {field}: {unique_values} unique values\")\n",
    "            if unique_values <= 10:\n",
    "                print(f\"    Values: {list(df[field].unique())}\")\n",
    "    \n",
    "    # Check for level/department data\n",
    "    dept_fields = [col for col in df.columns if any(word in col.lower() \n",
    "                  for word in ['department', 'dept', 'division', 'team', 'level'])]\n",
    "    if dept_fields:\n",
    "        print(f\"\\n🏢 Department/Level Fields: {dept_fields}\")\n",
    "        for field in dept_fields:\n",
    "            unique_values = df[field].nunique()\n",
    "            print(f\"  • {field}: {unique_values} unique values\")\n",
    "            if unique_values <= 15:\n",
    "                print(f\"    Values: {list(df[field].unique())}\")\n",
    "\n",
    "# Run exploration\n",
    "explore_user_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e170570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Utilities for Raffle System\n",
    "def create_raffle_export():\n",
    "    \"\"\"Create CSV export optimized for the raffle system\"\"\"\n",
    "    if not kpa_data:\n",
    "        print(\"❌ No user data available for export\")\n",
    "        return\n",
    "    \n",
    "    print(\"📋 Creating Raffle System Export\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Handle both list and dict structures\n",
    "    users_list = None\n",
    "    if isinstance(kpa_data, dict) and 'users' in kpa_data:\n",
    "        users_list = kpa_data['users']\n",
    "        print(f\"📊 Using users from API response ({len(users_list)} users)\")\n",
    "    elif isinstance(kpa_data, list):\n",
    "        users_list = kpa_data\n",
    "        print(f\"\udcca Using direct user list ({len(users_list)} users)\")\n",
    "    else:\n",
    "        print(\"❌ Unexpected data structure for export\")\n",
    "        return\n",
    "    \n",
    "    if not users_list:\n",
    "        print(\"❌ No users found for export\")\n",
    "        return\n",
    "    \n",
    "    df = pd.DataFrame(users_list)\n",
    "    \n",
    "    # Map fields to raffle system requirements\n",
    "    field_mapping = {}\n",
    "    \n",
    "    # Try to find name fields\n",
    "    name_candidates = [col for col in df.columns if 'name' in col.lower()]\n",
    "    if name_candidates:\n",
    "        # Prefer full name, then first + last\n",
    "        if any('full' in col.lower() for col in name_candidates):\n",
    "            field_mapping['Name'] = next(col for col in name_candidates if 'full' in col.lower())\n",
    "        elif 'name' in df.columns:\n",
    "            field_mapping['Name'] = 'name'\n",
    "        else:\n",
    "            field_mapping['Name'] = name_candidates[0]\n",
    "    \n",
    "    # Try to find location\n",
    "    location_candidates = [col for col in df.columns if any(word in col.lower() \n",
    "                          for word in ['location', 'site', 'office', 'building'])]\n",
    "    if location_candidates:\n",
    "        field_mapping['Location'] = location_candidates[0]\n",
    "    \n",
    "    # Try to find level/department\n",
    "    level_candidates = [col for col in df.columns if any(word in col.lower() \n",
    "                       for word in ['level', 'grade', 'position', 'title'])]\n",
    "    if level_candidates:\n",
    "        field_mapping['Level'] = level_candidates[0]\n",
    "    \n",
    "    # Try to find photo field\n",
    "    photo_candidates = []\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            url_count = df[col].astype(str).str.contains('http', na=False).sum()\n",
    "            if url_count > 0:\n",
    "                photo_candidates.append((col, url_count))\n",
    "    \n",
    "    if photo_candidates:\n",
    "        best_photo_field = max(photo_candidates, key=lambda x: x[1])[0]\n",
    "        field_mapping['Photo'] = best_photo_field\n",
    "    \n",
    "    print(\"\\n🎯 Field Mapping:\")\n",
    "    for raffle_field, kpa_field in field_mapping.items():\n",
    "        print(f\"  • {raffle_field}: {kpa_field}\")\n",
    "    \n",
    "    # Create export DataFrame\n",
    "    export_df = pd.DataFrame()\n",
    "    for raffle_field, kpa_field in field_mapping.items():\n",
    "        if kpa_field in df.columns:\n",
    "            export_df[raffle_field] = df[kpa_field]\n",
    "    \n",
    "    # Add any missing required columns\n",
    "    required_cols = ['Name', 'Location', 'Level']\n",
    "    for col in required_cols:\n",
    "        if col not in export_df.columns:\n",
    "            export_df[col] = 'Unknown'\n",
    "    \n",
    "    # Filter out users without names\n",
    "    if 'Name' in export_df.columns:\n",
    "        export_df = export_df[export_df['Name'].notna() & (export_df['Name'] != '')]\n",
    "    \n",
    "    print(f\"\\n📊 Export Summary:\")\n",
    "    print(f\"  • Total records: {len(export_df)}\")\n",
    "    print(f\"  • Columns: {list(export_df.columns)}\")\n",
    "    \n",
    "    # Show sample\n",
    "    print(f\"\\n📋 Sample Export Data:\")\n",
    "    print(export_df.head().to_string())\n",
    "    \n",
    "    # Save to CSV\n",
    "    filename = f\"kpa_raffle_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "    export_df.to_csv(filename, index=False)\n",
    "    print(f\"\\n💾 Exported to: {filename}\")\n",
    "    \n",
    "    return export_df\n",
    "\n",
    "# Create export\n",
    "raffle_export = create_raffle_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aba914a",
   "metadata": {},
   "source": [
    "## 📊 Summary & Next Steps\n",
    "\n",
    "This notebook provides a comprehensive toolkit for managing KPA user data:\n",
    "\n",
    "### ✅ What This Notebook Does:\n",
    "1. **🔧 Tests KPA API connectivity** - Verifies token and endpoint access\n",
    "2. **📊 Analyzes user data structure** - Shows available fields and data quality\n",
    "3. **📸 Tests photo integration** - Validates photo URLs work properly\n",
    "4. **🔍 Explores data** - Helps understand location, department, and level data\n",
    "5. **📋 Creates raffle exports** - Generates CSV files optimized for the raffle system\n",
    "\n",
    "### 🎯 Recommended Workflow:\n",
    "1. Run all cells from top to bottom\n",
    "2. Review the data analysis to understand your user base\n",
    "3. Use the export function to create raffle-ready CSV files\n",
    "4. Test photo loading to ensure images work in the raffle system\n",
    "\n",
    "### 💡 Tips for Raffle System:\n",
    "- The exported CSV can be directly uploaded to your raffle app\n",
    "- Photo URLs are tested to ensure they work reliably\n",
    "- Location and level data helps with targeted raffles\n",
    "- Regular exports help keep your raffle data current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c710aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple kernel test\n",
    "print(\"🧪 Kernel Test\")\n",
    "print(f\"KPA data type: {type(kpa_data)}\")\n",
    "if isinstance(kpa_data, dict):\n",
    "    print(f\"Keys: {list(kpa_data.keys())}\")\n",
    "print(\"✅ Kernel is responsive!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
